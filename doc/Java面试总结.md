# Java面试经验总结

## 1 Java内存模型
1. Java内存模型定义程序中各个变量的访问规则。即：在JVM中将变量存入内存和将变量从内存取出的底层细节。
站在编程人员角度来看，JMM规定了不同线程如何以及何时能够看到其它线程写入共享变量的值，以及如何同步对共享变量访问。

2. 线程的特性
原子性,有序性,可见性  
其中`synchronized`关键字能保证以上三种特性, `volatile`关键字只能保证 有序性和可见性, 原子性需要靠额外的加锁实现.

4. synchronized底层实现原理
搞清楚`synchronized`底层实现原理之前, 需要先明白Java对象的组成, 一个Java对象实例由三部分组成: ①对象头②实例数据③对齐填充. 其中在**对象头**的mark word字段中存储了锁的状态(无锁,偏向锁,轻量级锁,重量级锁). 每一个锁都对应一个monitor对象

5. Error和Exception区别及联系，可检查异常和不可检查异常
**答**：首先`Error`和`Exception`都是`Throwable`的子类，`Error`通常是JVM出现的错误，例如：OutofMemoryError, StackOverFlowError, ClassNotDefError等，Error错误级别比较严重，出现之后java程序一般就退出了，这些错误是不受检查异常，非代码性错误，因此应用程序也不应该去处理这些错误。
`Exception`是程序本身可以处理的异常，其又分为运行时异常和编译时异常。

## 2 Kafka如何保证“可靠性”和“一致性”
#### 2.1 可靠性
* 生产者数据不会丢失
Kafka有ACK机制，生产者往kafka队列中发送数据的时候，每次发送都有一个确认反馈机制，确保消息能够被正常收到。关于ACK的细节：  
  - **acks = 0**: 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息成功写入到了Kafka。这种情况下还是有可能发生错误，比如发送的数据不能被反序列化，这种模式下运行速度是非常快的。
  - **acks = 1**: 意味着如果Leader接收到消息并把它成功写入到分区文件中（不一同步到磁盘上）时会发送确认或者错误响应。在这个模式下，如果Leader挂了，正在发生新的Leader选举，生产者会收到一个`LeaderNotAvailableException`, 这就需要生产者恰当的处理这个异常重发数据来保证数据不丢失。其次，如果follower从leader中同步数据之前，leader挂了，这时还有可能会发生数据丢失，因为副本（Replica)中还没有来得及从Leader中同步最新的数据。
  - **acks = all(和request.required.acks = -1含义一样)**：Leader在返回确认或者错误响应之前，会等待所有Replica都收到消息。可以再和min.insync.replicas参数结合起来使用，就可以决定在返回确认之前至少几个副本能够收到消息，生产者会一直重试知道消息被成功提交，这种方式比较慢，因为生产者继续发送其它消息之前要等待所有副本都接收到当前的消息。

由此可见，需要根据实际情况来设置不同的acks，既能够保证性能又能保证数据的可靠性。

* 消费者数据不会丢失
消费者通过offset和commit来保证数据不丢失，如果不指定则默认是从latest标识位进行数据消费。kafka记录了每次消费的offset值，下次消费的时候接着上次的offset进行消费

* 保存的数据不会丢失
Kafka按照分区保存数据，每个分区有多个副本（默认3个），副本中其中一个是Leader，剩余的是Follower，Follower会定期从Leader中同步数据，当Leader挂了之后，消费者还能从Follower中继续读取到数据，这需要一个HighWater机制保证的。具体工作原理：  
每个分区的Leader会维护一个ISR列表，ISR列表中就是follower的broker编号，只有跟得上leader的follower副本才能够被加入到ISR列表中。只有所有ISR列表都同步的数据才能被consumer读取。

#### 2.2 一致性
这里的数据一致性是无论是老的Leader还是新选举出来的Leader，consumer读取到的数据均是一样的。Kafka是通过High Water mark机制保证的，如下图所示：
![](./images/1.png)
假设分区的副本数是3，replica0 是leader，replica1和replica2是follower，并且都在ISR列表里面。虽然replica0已经写入了message4，但是consumer只能读取到message2，因为所有的ISR都同步了message2，只有high water mark以上的数据才能够被consumer读取到。这样做的原因是Kafka任务还没有被足够多的副本复制的数据都是不安全的。如果consumer读取了leader中的message4，此时leader发生崩溃，replica1

## 3 Kafka如何保证“高性能”和“高吞吐”
1. 页缓存技术 + 磁盘顺序读写 + 零拷贝技术
> 生产者一端

Kafka是基于操作系统的页缓存来实现文件写入的。操作系统本身有一层缓存，叫做page cache, 是在内存里的缓存，也可以称之为os cache，在写入磁盘文件的时候，可以直接写入到这个os cache里，接下来由操作系统决定什么时候把缓存中的数据刷新到磁盘文件中。其次Kafka写入数据仅仅是将数据追加到文件末尾，而不是在文件的随机位置来修改数据，这就保证了写入方式是顺序写入的。**基于以上两点，Kafka就实现了写入数据的超高性能及吞吐量**。

>消费者一端

下面再来考虑消费者这一端，消费的时候实际上是从Kafka的磁盘文件中读取数据，然后发送给下游的消费者。如多读取消费的数据不在os cache 里面，则先从磁盘中读取，然后写入到os cache里面，接着从os cache中将数据拷贝到进程的内存空间中，再从进程缓存空间中将数据拷贝到socket缓存中，最后从socket缓存中提取数据发送到网卡，从网卡发送到下游消费者。其实①从os cache缓存中拷贝到用户进程的内存空间和②从用户进程内存空间拷贝到socket缓存中 这两次拷贝是没必要的, 而且为了这两次拷贝, 操作系统还发生了好几次上下文切换(核心态和用户态的切换), 这种读取数据的方式是非常消耗性能的. kafka为了解决这个问题, 引入了零拷贝技术, 直接从os cache中将数据拷贝到网卡，跳过了从os cache拷贝到用户进程缓存区 和 从用户进程缓存区拷贝到socket缓存，socket缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到socket缓存。这个过程大大提升了消费时对文件数据的读取性能。

如果Kafka集群经过良好的调优，其实会发现大量的数据都是直接写入os cache中，然后读取数据也是从os cache中读取的，相当于是Kafka完全基于内存提供数据的读和写，所以整体性能极高。

> 最后总结

通过上面介绍的 **生产者一端写入数据** 和 **消费者一端读取数据** Kafka所采取的思路可以看出，为什么Kafka能够具备这么高的性能，达到每秒几十万的吞吐量